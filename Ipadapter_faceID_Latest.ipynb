{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucianoRodriguez0764/ipadapter_faceid_colab/blob/main/Ipadapter_faceID_Latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing dependencies and download the IP-Adapter-FaceID-Plus-v2 model"
      ],
      "metadata": {
        "id": "OB5WejBfJtq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output as clear_output_py\n",
        "\n",
        "!pip install insightface\n",
        "!pip install onnxruntime\n",
        "!pip install diffusers\n",
        "!pip install git+https://github.com/tencent-ailab/IP-Adapter.git\n",
        "!pip install einops\n",
        "\n",
        "clear_output_py()"
      ],
      "metadata": {
        "id": "MQzuaaeAThi1",
        "collapsed": true
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O ip-adapter-faceid-plusv2_sd15.bin https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sd15.bin\n",
        "\n",
        "clear_output_py()"
      ],
      "metadata": {
        "id": "IoeXhrE8QZ_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the models to the pipeline"
      ],
      "metadata": {
        "id": "VtB54JeMJT_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, AutoencoderKL\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "v2 = True\n",
        "base_model_path = \"SG161222/Realistic_Vision_V6.0_B1_noVAE\"\n",
        "vae_model_path = \"stabilityai/sd-vae-ft-mse\"\n",
        "image_encoder_path = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
        "ip_ckpt = \"ip-adapter-faceid-plus_sd15.bin\" if not v2 else \"ip-adapter-faceid-plusv2_sd15.bin\"\n",
        "device = \"cuda\"\n",
        "\n",
        "noise_scheduler = DDIMScheduler(\n",
        "    num_train_timesteps=1000,\n",
        "    beta_start=0.00085,\n",
        "    beta_end=0.012,\n",
        "    beta_schedule=\"scaled_linear\",\n",
        "    clip_sample=False,\n",
        "    set_alpha_to_one=False,\n",
        "    steps_offset=1,\n",
        ")\n",
        "vae = AutoencoderKL.from_pretrained(vae_model_path).to(dtype=torch.float16)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    base_model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    scheduler=noise_scheduler,\n",
        "    vae=vae,\n",
        "    feature_extractor=None,\n",
        "    safety_checker=None\n",
        ")\n",
        "\n",
        "clear_output_py()"
      ],
      "metadata": {
        "id": "-vXAlOnhQjDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Face embeds and FaceID Image"
      ],
      "metadata": {
        "id": "N2XqayJMvHj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import shutil\n",
        "\n",
        "folder_path = \"/content/images\"\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"Deleted folder: {folder_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Folder not found: {folder_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "image_path = \"images/embeds\"\n",
        "image_path_face = \"images/face\"\n",
        "\n",
        "\n",
        "os.makedirs(image_path, exist_ok=True)\n",
        "os.makedirs(image_path_face, exist_ok=True)\n",
        "\n",
        "clear_output_py()"
      ],
      "metadata": {
        "id": "2ST_pK2RwGPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from insightface.app import FaceAnalysis\n",
        "from insightface.utils import face_align\n",
        "import torch\n",
        "import glob\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "app_lower = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "app_lower.prepare(ctx_id=0, det_size=(320, 320))\n",
        "\n",
        "clear_output_py()\n",
        "\n",
        "imgs = glob.glob(os.path.join(image_path, '*.*'))\n",
        "#imgs += glob.glob(os.path.join('images/face_2', '*.*'))\n",
        "\n",
        "# Collect all embeddings\n",
        "embeddings = []\n",
        "\n",
        "if len(imgs)==0:\n",
        "  print(\"You need to put face images on images/embeds for face-embedding and one image of face on images/face for face-id\")\n",
        "\n",
        "for i in range(len(imgs)):\n",
        "    print(imgs[i])\n",
        "    image = cv2.imread(imgs[i])\n",
        "    faces = app.get(image)\n",
        "\n",
        "    # Check if a face is detected\n",
        "    if faces:\n",
        "\n",
        "      face_image = face_align.norm_crop(image, landmark=faces[0].kps, image_size=224)\n",
        "      display(face_image)\n",
        "\n",
        "      faceid_embed = torch.from_numpy(faces[0].normed_embedding).unsqueeze(0)\n",
        "      embeddings.append(faceid_embed)\n",
        "    else:\n",
        "      print(\"face not detected with 640x640, trying with 320x320\")\n",
        "      faces = app_lower.get(image)\n",
        "      if faces:\n",
        "\n",
        "        face_image = face_align.norm_crop(image, landmark=faces[0].kps, image_size=224)\n",
        "        display(face_image)\n",
        "\n",
        "        faceid_embed = torch.from_numpy(faces[0].normed_embedding).unsqueeze(0)\n",
        "        embeddings.append(faceid_embed)\n",
        "      else:\n",
        "        print(\"face not detected.\")\n",
        "\n",
        "# Calculate the average embedding for the face ID\n",
        "use_image_weights = False\n",
        "weights = []\n",
        "weights = [elem/sum(weights) for elem in weights] # normalization\n",
        "\n",
        "if embeddings:\n",
        "    ### weights\n",
        "    if use_image_weights:\n",
        "      total = torch.zeros_like(embeddings[0])\n",
        "      for i in range(len(embeddings)):\n",
        "          if len(weights)==len(embeddings):\n",
        "              total.add_(embeddings[i]*weights[i])\n",
        "          else:\n",
        "              total.add_(embeddings[i]*(1/len(embeddings)))\n",
        "      faceid_embeds_avg = total / len(embeddings[i])\n",
        "    ###  mean weights\n",
        "    else:\n",
        "      faceid_embeds = torch.mean(torch.stack(embeddings), dim=0)\n",
        "\n",
        "    print(\"Collected face ID embedding\")\n",
        "else:\n",
        "    print(\"No faces detected in the images provided.\")"
      ],
      "metadata": {
        "id": "Q5cc28eQQrva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs_2 = glob.glob(os.path.join(image_path_face, '*.*'))\n",
        "\n",
        "image1 = cv2.imread(imgs_2[0])\n",
        "#image1 = cv2.resize(image1, (640, 640))\n",
        "\n",
        "faces1 = app.get(image1)\n",
        "\n",
        "\n",
        "if faces1:\n",
        "  print(\"face image detected.\")\n",
        "  face_image = face_align.norm_crop(image1, landmark=faces1[0].kps, image_size=224)\n",
        "  display(face_image)\n",
        "else:\n",
        "  print(\"face not detected with 640x640, trying with 320x320\")\n",
        "  faces1 = app_lower.get(image1)\n",
        "  if faces1:\n",
        "    print(\"face image detected.\")\n",
        "    face_image = face_align.norm_crop(image1, landmark=faces1[0].kps, image_size=224)\n",
        "    display(face_image)\n",
        "  else:\n",
        "    print(\"face not detected.\")"
      ],
      "metadata": {
        "id": "LVTd-8EkrP_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the functions"
      ],
      "metadata": {
        "id": "0KSkxVSMz5Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ip_adapter.ip_adapter_faceid import IPAdapterFaceIDPlus\n",
        "import ipywidgets as widgets\n",
        "import math\n",
        "\n",
        "ip_model = IPAdapterFaceIDPlus(pipe, image_encoder_path, ip_ckpt, device)\n",
        "\n",
        "clear_output_py()\n",
        "\n",
        "image_output = widgets.Output()\n",
        "text_output = widgets.Output()\n",
        "\n",
        "# UNUSED\n",
        "def display_images(images):\n",
        "    image_widgets = [widgets.Image(value=img._repr_png_()) for img in images]\n",
        "    display(widgets.HBox(image_widgets))\n",
        "\n",
        "def generate_images():\n",
        "\n",
        "  global ip_model, num_samples, num_inference_steps, guidance_scale, prompt, negative_prompt\n",
        "  global face_image, faceid_embeds, seed, width, height, s_scale, shortcut\n",
        "  global x_plot_generation, y_plot_generation, x_plot_parameter, y_plot_parameter\n",
        "  global x_plot_values, y_plot_values, xy_different_seeds\n",
        "  global image_output, text_output\n",
        "\n",
        "  if num_inference_steps==0:\n",
        "    num_inference_steps=1\n",
        "\n",
        "  if seed == -1:\n",
        "    seed = random.randint(1, 999999999)\n",
        "\n",
        "  with text_output:\n",
        "    print(\"samp:\",num_samples, \"steps:\",num_inference_steps, \"gui:\",guidance_scale,\"seed:\", seed,\"w:\", width, \"h:\",height,\"s_sc:\", s_scale,\n",
        "            \"v2:\",shortcut,\"xplot:\",x_plot_generation,\"yplot:\",y_plot_generation,\"x_par:\",x_plot_parameter,\"y_par:\",y_plot_parameter,\"x_vals:\",x_plot_values,\"y_vals:\",y_plot_values,\"xy_rnd:\",xy_different_seeds,\"prompt:\",prompt,\", neg prompt:\", negative_prompt)\n",
        "\n",
        "\n",
        "    rows = []\n",
        "\n",
        "\n",
        "    if x_plot_generation:\n",
        "      num_samples=1\n",
        "      if y_plot_generation:\n",
        "        images_array = []\n",
        "        for h in range(len(y_plot_values)):\n",
        "          images = []\n",
        "          if y_plot_parameter in globals():\n",
        "            if y_plot_parameter == \"face_image\" or y_plot_parameter == \"faceid_embeds\":\n",
        "              globals()[y_plot_parameter] = globals()[y_plot_values[h]]\n",
        "              print(y_plot_parameter,\"set to:\",y_plot_values[h])\n",
        "            else:\n",
        "              globals()[y_plot_parameter] = y_plot_values[h]\n",
        "              print(y_plot_parameter,\"set to:\",globals()[y_plot_parameter])\n",
        "          for i in range(len(x_plot_values)):\n",
        "            if x_plot_parameter == \"face_image\" or x_plot_parameter == \"faceid_embeds\":\n",
        "              globals()[x_plot_parameter] = globals()[x_plot_values[i]]\n",
        "              print(x_plot_parameter,\"set to:\",x_plot_values[i])\n",
        "            else:\n",
        "              globals()[x_plot_parameter] = x_plot_values[i]\n",
        "              print(x_plot_parameter,\"set to:\",globals()[x_plot_parameter])\n",
        "            if xy_different_seeds and i!=0:\n",
        "              seed = random.randint(1, 999999999)\n",
        "            print(\"Seed: \", seed)\n",
        "            generated_image = ip_model.generate(\n",
        "                prompt=prompt+\", \"+extra_prompt, negative_prompt=negative_prompt, face_image=face_image, faceid_embeds=faceid_embeds, num_samples=num_samples, width=width, height=height, num_inference_steps=num_inference_steps, seed=seed,\n",
        "                guidance_scale=guidance_scale, shortcut=shortcut, s_scale=s_scale,\n",
        "            )[0]\n",
        "            images.append(generated_image)\n",
        "          rows.append(widgets.HBox([widgets.Image(value=img._repr_png_()) for img in images]))\n",
        "        #images_array.append(images)\n",
        "\n",
        "        '''\n",
        "        for img in images_array:\n",
        "          display_images(img)\n",
        "        return\n",
        "        '''\n",
        "      else:\n",
        "        images = []\n",
        "        for i in range(len(x_plot_values)):\n",
        "          if x_plot_parameter == \"face_image\" or x_plot_parameter == \"faceid_embeds\":\n",
        "            globals()[x_plot_parameter] = globals()[x_plot_values[i]]\n",
        "            print(x_plot_parameter,\"set to:\",x_plot_values[i])\n",
        "          else:\n",
        "            globals()[x_plot_parameter] = x_plot_values[i]\n",
        "            print(x_plot_parameter,\"set to:\",globals()[x_plot_parameter])\n",
        "          if xy_different_seeds and i!=0:\n",
        "            seed = random.randint(1, 999999999)\n",
        "\n",
        "          print(\"Seed: \", seed)\n",
        "          images.extend(ip_model.generate(\n",
        "          prompt=prompt+\", \"+extra_prompt, negative_prompt=negative_prompt, face_image=face_image, faceid_embeds=faceid_embeds, num_samples=num_samples, width=width, height=height, num_inference_steps=num_inference_steps, seed=seed,\n",
        "          guidance_scale=guidance_scale, shortcut=True, s_scale=s_scale))\n",
        "        rows.append(widgets.HBox([widgets.Image(value=img._repr_png_()) for img in images]))\n",
        "    else:\n",
        "      print(\"Seed: \", seed)\n",
        "      images = ip_model.generate(\n",
        "          prompt=prompt+\", \"+extra_prompt, negative_prompt=negative_prompt, face_image=face_image, faceid_embeds=faceid_embeds, num_samples=num_samples, width=width, height=height, num_inference_steps=num_inference_steps, seed=seed,\n",
        "          guidance_scale=guidance_scale, shortcut=shortcut, s_scale=s_scale\n",
        "      )\n",
        "      rows.append(widgets.HBox([widgets.Image(value=img._repr_png_()) for img in images]))\n",
        "\n",
        "  with image_output:\n",
        "    for row in rows:\n",
        "      display(row)"
      ],
      "metadata": {
        "id": "M1O__MepE1ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "slider_style = {'description_width': '200px'}\n",
        "slider_layout = widgets.Layout(width='500px')\n",
        "\n",
        "text_input = widgets.Text(placeholder=\"Add prompts separated by commas\",style=slider_style, layout=slider_layout)\n",
        "add_button = widgets.Button(description=\"Add tag\")\n",
        "\n",
        "\n",
        "prompt_array = []\n",
        "neg_prompt_array = []\n",
        "x_parameter_value_array = []\n",
        "y_parameter_value_array = []\n",
        "\n",
        "tags_box = widgets.HBox([])\n",
        "\n",
        "def add_tag(b):\n",
        "    text = text_input.value\n",
        "    tags = text.split(\",\")\n",
        "\n",
        "    for i in range(len(tags)):\n",
        "        tags[i] = tags[i].strip()\n",
        "\n",
        "    for tag in tags:\n",
        "      if tag!=\"\":\n",
        "        tag_wi = widgets.HBox([\n",
        "            widgets.HTML(value=f\"<b>{tag}</b>\"),\n",
        "            widgets.Button(description=\"x\", layout=widgets.Layout(width='30px'))\n",
        "        ])\n",
        "        prompt_array.append(tag)\n",
        "\n",
        "        tags_box.children = list(tags_box.children) + [tag_wi]\n",
        "        tag_wi.children[1].on_click(lambda b, tag_wi=tag_wi, tag=tag: remove_tag(tag_wi,tag))\n",
        "    text_input.value = \"\"\n",
        "\n",
        "def remove_tag(tag_wi,tag):\n",
        "    global prompt_array\n",
        "    tags_box.children = [child for child in tags_box.children if child != tag_wi]\n",
        "    prompt_array = [x for x in prompt_array if x != tag]\n",
        "\n",
        "add_button.on_click(add_tag)\n",
        "\n",
        "######## NEGATIVE PROMPTS ###########\n",
        "\n",
        "text_input_neg = widgets.Text(placeholder=\"Add negative prompts separated by commas\",style=slider_style, layout=slider_layout)\n",
        "add_button_neg = widgets.Button(description=\"Add tag\")\n",
        "\n",
        "tags_box_neg = widgets.HBox([])\n",
        "\n",
        "def add_tag_neg(b):\n",
        "    text = text_input_neg.value\n",
        "    tags = text.split(\",\")\n",
        "\n",
        "    for i in range(len(tags)):\n",
        "        tags[i] = tags[i].strip()\n",
        "\n",
        "    for tag in tags:\n",
        "      if tag!=\"\":\n",
        "        tag_wi = widgets.HBox([\n",
        "            widgets.HTML(value=f\"<b>{tag}</b>\"),\n",
        "            widgets.Button(description=\"x\", layout=widgets.Layout(margin=\"0px, 0px, 0px, 5px\",width='30px'))\n",
        "        ])\n",
        "        neg_prompt_array.append(tag)\n",
        "\n",
        "        tags_box_neg.children = list(tags_box_neg.children) + [tag_wi]\n",
        "        tag_wi.children[1].on_click(lambda b, tag_wi=tag_wi, tag=tag: remove_tag_neg(tag_wi,tag))\n",
        "    text_input_neg.value = \"\"\n",
        "\n",
        "\n",
        "def remove_tag_neg(tag_wi,tag):\n",
        "    global neg_prompt_array\n",
        "    tags_box_neg.children = [child for child in tags_box_neg.children if child != tag_wi]\n",
        "    neg_prompt_array = [x for x in neg_prompt_array if x != tag]\n",
        "\n",
        "add_button_neg.on_click(add_tag_neg)\n",
        "\n",
        "\n",
        "########### x plot generation ###########\n",
        "\n",
        "\n",
        "text_input_x = widgets.Text(placeholder=\"X Parameter values\", disabled=True)\n",
        "add_button_x = widgets.Button(description=\"Add value\", disabled=True)\n",
        "\n",
        "tags_box_x = widgets.HBox([])\n",
        "\n",
        "def add_tag_x(b):\n",
        "    text = text_input_x.value\n",
        "    tags = text.split(\",\")\n",
        "\n",
        "    for i in range(len(tags)):\n",
        "        tags[i] = tags[i].strip()\n",
        "\n",
        "    for tag in tags:\n",
        "      if tag!=\"\":\n",
        "        tag_wi = widgets.HBox([\n",
        "            widgets.HTML(value=f\"<b>{tag}</b>\"),\n",
        "            widgets.Button(description=\"x\", layout=widgets.Layout(width='30px'))\n",
        "        ])\n",
        "        x_parameter_value_array.append(tag)\n",
        "        tags_box_x.children = list(tags_box_x.children) + [tag_wi]\n",
        "        tag_wi.children[1].on_click(lambda b, tag_wi=tag_wi, tag=tag: remove_tag_x(tag_wi,tag))\n",
        "    text_input_x.value = \"\"\n",
        "\n",
        "\n",
        "\n",
        "def remove_tag_x(tag_wi,tag):\n",
        "    global x_parameter_value_array\n",
        "    tags_box_x.children = [child for child in tags_box_x.children if child != tag_wi]\n",
        "\n",
        "    if x_plot_parameter == \"num_inference_steps\":\n",
        "      tag = int(tag)\n",
        "    elif x_plot_parameter in [\"guidance_scale\", \"s_scale\"]:\n",
        "      tag = float(tag)\n",
        "\n",
        "    x_parameter_value_array = [x for x in x_parameter_value_array if x != tag]\n",
        "\n",
        "add_button_x.on_click(add_tag_x)\n",
        "\n",
        "########### y plot generation ###########\n",
        "\n",
        "\n",
        "text_input_y = widgets.Text(placeholder=\"Y Parameter values\", disabled=True)\n",
        "add_button_y = widgets.Button(description=\"Add value\", disabled=True)\n",
        "\n",
        "tags_box_y = widgets.HBox([])\n",
        "\n",
        "def add_tag_y(b):\n",
        "    text = text_input_y.value\n",
        "    tags = text.split(\",\")\n",
        "\n",
        "    for i in range(len(tags)):\n",
        "        tags[i] = tags[i].strip()\n",
        "\n",
        "    for tag in tags:\n",
        "      if tag!=\"\":\n",
        "        tag_wi = widgets.HBox([\n",
        "            widgets.HTML(value=f\"<b>{tag}</b>\"),\n",
        "            widgets.Button(description=\"x\", layout=widgets.Layout(width='30px'))\n",
        "        ])\n",
        "        y_parameter_value_array.append(tag)\n",
        "        tags_box_y.children = list(tags_box_y.children) + [tag_wi]\n",
        "        tag_wi.children[1].on_click(lambda b, tag_wi=tag_wi, tag=tag: remove_tag_y(tag_wi,tag))\n",
        "    text_input_y.value = \"\"\n",
        "\n",
        "def remove_tag_y(tag_wi,tag):\n",
        "    global y_parameter_value_array\n",
        "    tags_box_y.children = [child for child in tags_box_y.children if child != tag_wi]\n",
        "\n",
        "    if y_plot_parameter == \"num_inference_steps\":\n",
        "      tag = int(tag)\n",
        "    elif y_plot_parameter in [\"guidance_scale\", \"s_scale\"]:\n",
        "      tag = float(tag)\n",
        "\n",
        "    y_parameter_value_array = [y for y in y_parameter_value_array if y != tag]\n",
        "\n",
        "add_button_y.on_click(add_tag_y)"
      ],
      "metadata": {
        "id": "ZARiTWBV2qG3"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate images with the IP-Adapter"
      ],
      "metadata": {
        "id": "9xsAOehQ0Fhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "import random\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "\n",
        "#### DEFAULT SETTINGS ####\n",
        "\n",
        "width=512\n",
        "height=512\n",
        "num_samples=1\n",
        "num_inference_steps=30\n",
        "guidance_scale = 3\n",
        "s_scale = 1\n",
        "x_plot_generation = False\n",
        "y_plot_generation = False\n",
        "x_plot_values = []\n",
        "y_plot_values = []\n",
        "tags_box = widgets.HBox([])\n",
        "tags_box_neg = widgets.HBox([])\n",
        "tags_box_x = widgets.HBox([])\n",
        "tags_box_y = widgets.HBox([])\n",
        "prompt_array = []\n",
        "neg_prompt_array = []\n",
        "x_parameter_value_array = []\n",
        "y_parameter_value_array = []\n",
        "x_plot_parameter = \"num_inference_steps\"\n",
        "y_plot_parameter = \"guidance_scale\"\n",
        "initial_prompt = \"\"\n",
        "extra_prompt = \"\"\n",
        "initial_negative_prompt = \"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime), text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, nfsw, extra legs, fused fingers, too many fingers, long neck\"\n",
        "shortcut = True\n",
        "xy_different_seeds = False\n",
        "face_id_embeds = faceid_embeds\n",
        "face_image = face_image\n",
        "seed = -1\n",
        "\n",
        "width_selector = widgets.Dropdown(\n",
        "    options=[256, 288, 384, 512, 640, 768, 1024],\n",
        "    value=512,\n",
        "    description='Width:',\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "height_selector = widgets.Dropdown(\n",
        "    options=[256, 288, 384, 512, 640, 768, 1024],\n",
        "    value=512,\n",
        "    description='Height:',\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "\n",
        "def on_size_change(change):\n",
        "    global width, height\n",
        "    #print(f\"Selected Width: {width_selector.value}, Selected Height: {height_selector.value}\")\n",
        "    width = width_selector.value\n",
        "    height = height_selector.value\n",
        "\n",
        "width_selector.observe(on_size_change, names='value')\n",
        "height_selector.observe(on_size_change, names='value')\n",
        "\n",
        "num_inference_steps_slider = widgets.IntSlider(\n",
        "    value=30,\n",
        "    min=0,\n",
        "    max=100,\n",
        "    step=5,\n",
        "    description='Num inference steps:',\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "def on_num_inference_steps_scale_change(change):\n",
        "    global num_inference_steps\n",
        "    num_inference_steps = num_inference_steps_slider.value\n",
        "\n",
        "num_inference_steps_slider.observe(on_num_inference_steps_scale_change, names='value')\n",
        "\n",
        "num_samples_slider = widgets.IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=6,\n",
        "    step=1,\n",
        "    description='Num samples:',\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "def on_num_samples_scale_change(change):\n",
        "    global num_samples\n",
        "    num_samples = num_samples_slider.value\n",
        "\n",
        "num_samples_slider.observe(on_num_samples_scale_change, names='value')\n",
        "\n",
        "guidance_scale_slider = widgets.FloatSlider(\n",
        "    value=3,\n",
        "    min=0.5,\n",
        "    max=15,\n",
        "    step=0.5,\n",
        "    description='Guidance Scale:',\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "def on_guidance_scale_change(change):\n",
        "    global guidance_scale\n",
        "    guidance_scale = guidance_scale_slider.value\n",
        "\n",
        "guidance_scale_slider.observe(on_guidance_scale_change, names='value')\n",
        "\n",
        "seed_slider = widgets.IntSlider(\n",
        "    value=-1,\n",
        "    min=-1,\n",
        "    max=999999999,\n",
        "    step=1,\n",
        "    description='Seed:',\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "def on_seed_change(change):\n",
        "    global seed\n",
        "    seed = seed_slider.value\n",
        "\n",
        "seed_slider.observe(on_seed_change, names='value')\n",
        "\n",
        "s_scale_slider = widgets.FloatSlider(\n",
        "    value=1,\n",
        "    min=0.1,\n",
        "    max=3,\n",
        "    step=0.1,\n",
        "    description='s_scale:',\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "def on_s_scale_change(change):\n",
        "    global s_scale\n",
        "    s_scale = s_scale_slider.value\n",
        "    #print(f\"Selected Guidance Scale: {guidance_scale_slider.value}\")\n",
        "\n",
        "s_scale_slider.observe(on_s_scale_change, names='value')\n",
        "\n",
        "x_plot_selector = widgets.Dropdown(\n",
        "    options=['num_inference_steps', 'guidance_scale','s_scale','extra_prompt','face_image'],\n",
        "    value='num_inference_steps',\n",
        "    description='x plot parameter:',\n",
        "    disabled=True,\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "y_plot_selector = widgets.Dropdown(\n",
        "    options=['num_inference_steps', 'guidance_scale','s_scale','extra_prompt','face_image'],\n",
        "    value='guidance_scale',\n",
        "    description='y plot parameter:',\n",
        "    disabled=True,\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "xy_randomseed_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='random seed when XY plot',\n",
        "    disabled=False,\n",
        "    indent=True,\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "def y_plot_on_change(change):\n",
        "    global y_plot_parameter\n",
        "    y_plot_parameter = y_plot_selector.value\n",
        "\n",
        "def x_plot_on_change(change):\n",
        "    global x_plot_parameter\n",
        "    x_plot_parameter = x_plot_selector.value\n",
        "\n",
        "def xy_randomseed_checkbox_on_change(change):\n",
        "    global xy_different_seeds\n",
        "    xy_different_seeds = xy_randomseed_checkbox.value\n",
        "\n",
        "x_plot_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='x plot generation',\n",
        "    disabled=False,\n",
        "    indent=True,\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "y_plot_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='y plot generation',\n",
        "    disabled=False,\n",
        "    indent=True,\n",
        "    style=slider_style,\n",
        "    layout=slider_layout\n",
        ")\n",
        "\n",
        "text_output.clear_output()\n",
        "image_output.clear_output()\n",
        "\n",
        "x_plot_selector.observe(x_plot_on_change, names='value')\n",
        "y_plot_selector.observe(y_plot_on_change, names='value')\n",
        "xy_randomseed_checkbox.observe(xy_randomseed_checkbox_on_change, names='value')\n",
        "\n",
        "def x_plot_checkbox_change(change):\n",
        "    global x_plot_generation\n",
        "    x_plot_generation = x_plot_checkbox.value\n",
        "\n",
        "    x_plot_selector.disabled= not x_plot_checkbox.value\n",
        "    text_input_x.disabled= not x_plot_checkbox.value\n",
        "    add_button_x.disabled= not x_plot_checkbox.value\n",
        "    tags_box_x.disabled= not x_plot_checkbox.value\n",
        "\n",
        "def y_plot_checkbox_change(change):\n",
        "    global y_plot_generation\n",
        "    y_plot_generation = y_plot_checkbox.value\n",
        "\n",
        "    y_plot_selector.disabled= not y_plot_checkbox.value\n",
        "    text_input_y.disabled= not y_plot_checkbox.value\n",
        "    add_button_y.disabled= not y_plot_checkbox.value\n",
        "    tags_box_y.disabled= not y_plot_checkbox.value\n",
        "\n",
        "x_plot_checkbox.observe(x_plot_checkbox_change, names='value')\n",
        "y_plot_checkbox.observe(y_plot_checkbox_change, names='value')\n",
        "\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate images\")\n",
        "generate_button.layout = widgets.Layout(width='300px', height=\"40px\")\n",
        "\n",
        "def on_generate_click(b):\n",
        "    global ip_model, num_samples, num_inference_steps, guidance_scale, prompt, negative_prompt, face_image, faceid_embeds, seed, width, height, s_scale, shortcut,x_plot_generation,y_plot_generation,x_plot_parameter,y_plot_parameter,x_plot_values,y_plot_values,xy_different_seeds,prompt_array,neg_prompt_array,x_parameter_value_array,y_parameter_value_array\n",
        "    prompt = initial_prompt+\", \"+\", \".join(prompt_array)\n",
        "    negative_prompt = initial_negative_prompt+\", \"+\", \".join(neg_prompt_array)\n",
        "\n",
        "    if x_plot_parameter in [\"guidance_scale\", \"s_scale\"] and x_plot_generation:\n",
        "      x_plot_values = [float(value) for value in x_parameter_value_array]\n",
        "      x_parameter_value_array = [float(value) for value in x_parameter_value_array]\n",
        "    elif x_plot_parameter==\"num_inference_steps\":\n",
        "      x_plot_values = [int(value) for value in x_parameter_value_array]\n",
        "      x_parameter_value_array = [int(value) for value in x_parameter_value_array]\n",
        "    else:\n",
        "      x_plot_values = x_parameter_value_array\n",
        "\n",
        "    if y_plot_parameter in [\"guidance_scale\", \"s_scale\"] and y_plot_generation:\n",
        "      y_plot_values = [float(value) for value in y_parameter_value_array]\n",
        "      y_parameter_value_array = [float(value) for value in y_parameter_value_array]\n",
        "    elif y_plot_parameter==\"num_inference_steps\":\n",
        "      y_plot_values = [int(value) for value in y_parameter_value_array]\n",
        "      y_parameter_value_array = [int(value) for value in y_parameter_value_array]\n",
        "    else:\n",
        "      y_plot_values = y_parameter_value_array\n",
        "\n",
        "    text_output.clear_output()\n",
        "    image_output.clear_output()\n",
        "    generate_images()\n",
        "\n",
        "    seed = -1\n",
        "\n",
        "\n",
        "generate_button.on_click(on_generate_click)\n",
        "generate_button_container = widgets.HBox([generate_button])\n",
        "generate_button_container.layout = widgets.Layout(width='500px',justify_content=\"center\",display=\"flex\")\n",
        "\n",
        "\n",
        "add_button_container = widgets.HBox([add_button])\n",
        "add_button_container.layout = widgets.Layout(width='500px',justify_content=\"center\", display=\"flex\")\n",
        "\n",
        "add_button_neg_container = widgets.HBox([add_button_neg])\n",
        "add_button_neg_container.layout = widgets.Layout(width='500px',justify_content=\"center\", display=\"flex\")\n",
        "\n",
        "display(text_input, add_button_container, tags_box)\n",
        "display(text_input_neg, add_button_neg_container, tags_box_neg)\n",
        "\n",
        "display(width_selector, height_selector,num_samples_slider, num_inference_steps_slider, guidance_scale_slider,\n",
        "        seed_slider, s_scale_slider)\n",
        "\n",
        "display(x_plot_checkbox,y_plot_checkbox,x_plot_selector,y_plot_selector,xy_randomseed_checkbox)\n",
        "\n",
        "add_button_x_container = widgets.HBox([add_button_x])\n",
        "add_button_x_container.layout = widgets.Layout(width='500px',justify_content=\"center\", display=\"flex\")\n",
        "add_button_y_container = widgets.HBox([add_button_y])\n",
        "add_button_y_container.layout = widgets.Layout(width='500px',justify_content=\"center\", display=\"flex\")\n",
        "text_input_x_container = widgets.HBox([text_input_x])\n",
        "text_input_x_container.layout = widgets.Layout(width='500px',justify_content=\"center\", display=\"flex\")\n",
        "text_input_y_container = widgets.HBox([text_input_y])\n",
        "text_input_y_container.layout = widgets.Layout(width='500px',justify_content=\"center\", display=\"flex\")\n",
        "\n",
        "display(text_input_x_container, add_button_x_container, tags_box_x)\n",
        "display(text_input_y_container, add_button_y_container, tags_box_y)\n",
        "\n",
        "display(generate_button_container)\n",
        "\n",
        "display(text_output, image_output)"
      ],
      "metadata": {
        "id": "TjfOTc7FtsWy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}